{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os, random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "\n",
    "import keras\n",
    "from keras.applications import mobilenet_v2, imagenet_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4096)\n",
    "tensorflow.set_random_seed(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = '../../../Workspace/bad-cat'\n",
    "IMAGES_DIR = os.path.join(WORKING_DIR, 'train_images')\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, 'out')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "KERAS_MODEL_FILE = os.path.join(OUTPUT_DIR, 'mobilenet_classifier.h5')\n",
    "TFLITE_MODEL_FILE = os.path.join(OUTPUT_DIR, 'mobilenet_classifier.tflite')\n",
    "LABELS_FILE = os.path.join(OUTPUT_DIR, 'mobilenet_labels.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_W = 224\n",
    "IMAGE_H = 224\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=mobilenet_v2.preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "training_generator = image_generator.flow_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    target_size=(IMAGE_W, IMAGE_H),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = image_generator.flow_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    target_size=(IMAGE_W, IMAGE_H),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item[0] for item in sorted(training_generator.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "import pickle\n",
    "with open(LABELS_FILE, 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(image_dir, grid_width, grid_height):\n",
    "    image_paths = glob.glob(IMAGES_DIR + '/*/*.jpg')\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_height, grid_width, subplot_kw={'xticks': [], 'yticks': []})\n",
    "    fig.set_size_inches(20, 30)\n",
    "    \n",
    "    count = grid_width * grid_height\n",
    "    for ax, path in zip(axes.flat, image_paths[0:count]):\n",
    "        base, _ = os.path.split(path)\n",
    "        category = os.path.basename(base)\n",
    "        image = cv2.imread(path)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(category)\n",
    "\n",
    "plot_samples(IMAGES_DIR, 6, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = mobilenet_v2.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMAGE_W,IMAGE_H,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = mobilenet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(training_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=mobilenet_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_EPOCHS = 10\n",
    "FINETUNE_EPOCHS = 10\n",
    "\n",
    "INITIAL_LR = 0.001\n",
    "FINETUNE_LR = INITIAL_LR / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, learning_rate):\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer = SGD(lr=learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model.fit_generator(\n",
    "        training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=training_generator.samples / training_generator.batch_size,\n",
    "        validation_steps=validation_generator.samples / validation_generator.batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(KERAS_MODEL_FILE, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Top Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hist = train(TOP_EPOCHS, INITIAL_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenet_model.layers[:100]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finetune_hist = train(FINETUNE_EPOCHS, FINETUNE_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export as TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tensorflow.contrib.lite.TFLiteConverter.from_keras_model_file(KERAS_MODEL_FILE)\n",
    "converted_model = converter.convert()\n",
    "with open(TFLITE_MODEL_FILE, 'wb') as f:\n",
    "    f.write(converted_model)\n",
    "    \n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_hist = finetune_hist = H\n",
    "N = np.arange(0, TOP_EPOCHS + FINETUNE_EPOCHS)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "ax1.plot(N, top_hist.history[\"loss\"] + finetune_hist.history[\"loss\"], label=\"Training Loss\")\n",
    "ax1.plot(N, top_hist.history[\"val_loss\"] + finetune_hist.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "ax1.set(title=\"Loss\", xlabel='Epoch', ylabel='Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(N, top_hist.history[\"acc\"] + finetune_hist.history[\"acc\"], label=\"Training Accuracy\")\n",
    "ax2.plot(N, top_hist.history[\"val_acc\"] + finetune_hist.history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "ax2.set(title='Accuracy', xlabel='Epoch', ylabel='Accuracy', ylim=(0,1))\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(KERAS_MODEL_FILE)\n",
    "\n",
    "predictions = model.predict_generator(validation_generator, steps=validation_generator.samples / validation_generator.batch_size)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = validation_generator.class_indices.keys()\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "print(metrics.confusion_matrix(y_true=true_classes, y_pred=predictions))\n",
    "print(metrics.classification_report(true_classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
